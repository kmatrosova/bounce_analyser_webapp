# Bounce Checker

This project classifies email bounces by identifying both their **source** (e.g. mailbox full, address not found) and **reason** (underlying cause). It supports training, evaluation, and prediction workflows. Each user maintains their own local data structure.

---

## ğŸ“‚ Project Structure

```
bounce_analyser/
â”œâ”€â”€ config.py
â”œâ”€â”€ data/                        # ğŸ”§ Must be created by the user (not versioned)
â”‚   â”œâ”€â”€ raw/
â”‚   â”œâ”€â”€ inference/
â”‚   â””â”€â”€ train/
â”‚       â”œâ”€â”€ preprocessed/
â”‚       â”‚   â”œâ”€â”€ source/
â”‚       â”‚   â””â”€â”€ reason/
â”‚       â”œâ”€â”€ labels/
â”‚       â”‚   â”œâ”€â”€ source/
â”‚       â”‚   â””â”€â”€ reason/
â”‚       â”œâ”€â”€ logs/
â”‚       â””â”€â”€ predictions/
â”œâ”€â”€ training/
â”‚   â””â”€â”€ bounce_trainer.py
â”œâ”€â”€ evaluation/
â”‚   â””â”€â”€ evaluator.py
â”œâ”€â”€ inference/
â”‚   â””â”€â”€ bounce_inference.py
â”œâ”€â”€ utils.py
â”œâ”€â”€ train.py                     # Training entrypoint
â”œâ”€â”€ evaluate.py                  # Evaluation entrypoint
â”œâ”€â”€ predict.py                   # Inference entrypoint
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ setup.py
â”œâ”€â”€ .env                         # Optional: environment variables (e.g. default paths)
â”œâ”€â”€ .gitignore                   # Excludes data, logs, models, etc.
```

---

## âš™ï¸ Setup

Install dependencies:

```bash
pip install -r requirements.txt
```

Set up a `.env` file if needed for default paths or keys.

Create a local `data/` folder with this structure:

```
data/
â”œâ”€â”€ raw/
â”œâ”€â”€ inference/
â””â”€â”€ train/
    â”œâ”€â”€ preprocessed/
    â”‚   â”œâ”€â”€ source/
    â”‚   â””â”€â”€ reason/
    â”œâ”€â”€ labels/
    â”‚   â”œâ”€â”€ source/
    â”‚   â””â”€â”€ reason/
    â”œâ”€â”€ logs/
    â””â”€â”€ predictions/
```

This folder is not tracked in version control and is specific to each user.

---

## ğŸ‹ï¸â€â™‚ï¸ Training

Train a model for a specific task (`source` or `reason`) and dataset:

```bash
python -m train \
  --model_type <source|reason> \
  --dataset_name <dataset_name>
```

Outputs:
- Model saved in `training/`
- Train/test splits saved in `data/train/labels/`
- Logs saved in `data/train/logs/`

---

## ğŸ“Š Evaluation

Evaluate a trained model using its `run_id`:

```bash
python -m evaluate \
  --model_type <source|reason> \
  --dataset_name <dataset_name> \
  --run_id <your_run_id>
```

Predictions are saved in:

```
data/train/predictions/<source|reason>/
```

---

## ğŸ” Inference

Classify new bounce messages using a saved model:

```bash
python -m predict \
  --model_type <source|reason> \
  --model_path training/<your_run_id>_<model_type>_model.pkl \
  --input_path data/inference/<your_file>.jsonl
```

Results are saved in the same folder as the input.

---

## âœ… Notes

- Tasks supported: `source`, `reason`
- Each training run generates a timestamped `run_id`
- All paths and settings can be customized in `config.py` or `.env`
- `data/` is user-specific and not included in the repo
